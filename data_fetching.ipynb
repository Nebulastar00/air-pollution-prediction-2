{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AQS Data Fetching\n",
    "----\n",
    "After our preliminary investigation launched in the [previous notebook](preliminary_exploration.ipynb), we have deduced that we can pretty easily fetch and filter a large quantity of daily readings data for at least carbon monoxide in a couple of states. Now, we aim to fetch air quality data for all of the AQI defined pollutants for all 50 states, during the time period between 2013 and 2018.\n",
    "\n",
    "To start, let's import our needed libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyaqs import AQSFetcher\n",
    "from time import sleep\n",
    "from random import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "aqs_fetcher = AQSFetcher('bbjornstad.flatiron@gmail.com', 'ochrefox21')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_codes = aqs_fetcher.get_state_codes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>parameter_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42101</td>\n",
       "      <td>Carbon monoxide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42401</td>\n",
       "      <td>Sulfur dioxide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42602</td>\n",
       "      <td>Nitrogen dioxide (NO2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44201</td>\n",
       "      <td>Ozone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81102</td>\n",
       "      <td>PM10 Total 0-10um STP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>88101</td>\n",
       "      <td>PM2.5 - Local Conditions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>88502</td>\n",
       "      <td>Acceptable PM2.5 AQI &amp; Speciation Mass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    code                   parameter_description\n",
       "0  42101                         Carbon monoxide\n",
       "1  42401                          Sulfur dioxide\n",
       "2  42602                  Nitrogen dioxide (NO2)\n",
       "3  44201                                   Ozone\n",
       "4  81102                   PM10 Total 0-10um STP\n",
       "5  88101                PM2.5 - Local Conditions\n",
       "6  88502  Acceptable PM2.5 AQI & Speciation Mass"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aqi_parameters = aqs_fetcher.get_parameter_list_by_class('AQI POLLUTANTS')\n",
    "aqi_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, now everything that we will need to cache the EPA AQS API has been appropriately stored here. We can now loop over each of the states and query for the data on these AQI pollutants. For ease of further use, we will also save these data in raw format as CSV files in the [`data`](./data/) folder. This will allow us to easily retrieve the data in raw format if needed in the future, without needing to further query the API, gaining in efficiency and practicality for the API maintainers. Let's start by setting the date bounds to variables to increase readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdate = 20130101\n",
    "edate = 20181231"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can loop over the codes in our state code lists to fetch raw dataframes that we can store as CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 01 (Alabama) -- 42101\n",
      "Saved 02 (Alaska) -- 42101\n",
      "Saved 04 (Arizona) -- 42101\n",
      "Saved 05 (Arkansas) -- 42101\n",
      "Saved 06 (California) -- 42101\n",
      "Saved 08 (Colorado) -- 42101\n",
      "Saved 09 (Connecticut) -- 42101\n",
      "Saved 10 (Delaware) -- 42101\n",
      "Saved 11 (District Of Columbia) -- 42101\n",
      "Saved 12 (Florida) -- 42101\n",
      "Saved 13 (Georgia) -- 42101\n",
      "Saved 15 (Hawaii) -- 42101\n",
      "Saved 16 (Idaho) -- 42101\n",
      "Saved 17 (Illinois) -- 42101\n",
      "Saved 18 (Indiana) -- 42101\n",
      "Saved 19 (Iowa) -- 42101\n",
      "Saved 20 (Kansas) -- 42101\n",
      "Saved 21 (Kentucky) -- 42101\n",
      "Saved 22 (Louisiana) -- 42101\n",
      "Saved 23 (Maine) -- 42101\n",
      "Saved 24 (Maryland) -- 42101\n",
      "Saved 25 (Massachusetts) -- 42101\n",
      "Saved 26 (Michigan) -- 42101\n",
      "Saved 27 (Minnesota) -- 42101\n",
      "Saved 28 (Mississippi) -- 42101\n",
      "Saved 29 (Missouri) -- 42101\n",
      "Saved 30 (Montana) -- 42101\n",
      "Saved 31 (Nebraska) -- 42101\n",
      "Saved 32 (Nevada) -- 42101\n",
      "Saved 33 (New Hampshire) -- 42101\n",
      "Saved 34 (New Jersey) -- 42101\n",
      "Saved 35 (New Mexico) -- 42101\n",
      "Saved 36 (New York) -- 42101\n",
      "Saved 37 (North Carolina) -- 42101\n",
      "Saved 38 (North Dakota) -- 42101\n",
      "Saved 39 (Ohio) -- 42101\n",
      "Saved 40 (Oklahoma) -- 42101\n",
      "Saved 41 (Oregon) -- 42101\n",
      "Saved 42 (Pennsylvania) -- 42101\n",
      "Saved 44 (Rhode Island) -- 42101\n",
      "Saved 45 (South Carolina) -- 42101\n",
      "Saved 46 (South Dakota) -- 42101\n",
      "Saved 47 (Tennessee) -- 42101\n",
      "Saved 48 (Texas) -- 42101\n",
      "Saved 49 (Utah) -- 42101\n",
      "Saved 50 (Vermont) -- 42101\n",
      "Saved 51 (Virginia) -- 42101\n",
      "Saved 53 (Washington) -- 42101\n",
      "Saved 54 (West Virginia) -- 42101\n",
      "Saved 55 (Wisconsin) -- 42101\n",
      "Saved 56 (Wyoming) -- 42101\n",
      "No matching data could be found!\n",
      "No data found for 66 -- 42101\n",
      "Saved 72 (Puerto Rico) -- 42101\n",
      "No matching data could be found!\n",
      "No data found for 78 -- 42101\n",
      "Saved 80 (Country Of Mexico) -- 42101\n",
      "Bad URL!\n",
      "No data found for CC -- 42101\n",
      "Saved 01 (Alabama) -- 42401\n",
      "Saved 02 (Alaska) -- 42401\n",
      "Saved 04 (Arizona) -- 42401\n",
      "Saved 05 (Arkansas) -- 42401\n",
      "Saved 06 (California) -- 42401\n",
      "Saved 08 (Colorado) -- 42401\n",
      "Saved 09 (Connecticut) -- 42401\n",
      "Saved 10 (Delaware) -- 42401\n",
      "Saved 11 (District Of Columbia) -- 42401\n",
      "Saved 12 (Florida) -- 42401\n",
      "Saved 13 (Georgia) -- 42401\n",
      "Saved 15 (Hawaii) -- 42401\n",
      "Saved 16 (Idaho) -- 42401\n",
      "Saved 17 (Illinois) -- 42401\n",
      "Saved 18 (Indiana) -- 42401\n",
      "Saved 19 (Iowa) -- 42401\n",
      "Saved 20 (Kansas) -- 42401\n",
      "Saved 21 (Kentucky) -- 42401\n",
      "Saved 22 (Louisiana) -- 42401\n",
      "Saved 23 (Maine) -- 42401\n",
      "Saved 24 (Maryland) -- 42401\n",
      "Saved 25 (Massachusetts) -- 42401\n",
      "Saved 26 (Michigan) -- 42401\n",
      "Saved 27 (Minnesota) -- 42401\n",
      "Saved 28 (Mississippi) -- 42401\n",
      "Saved 29 (Missouri) -- 42401\n",
      "Saved 30 (Montana) -- 42401\n",
      "Saved 31 (Nebraska) -- 42401\n",
      "Saved 32 (Nevada) -- 42401\n",
      "Saved 33 (New Hampshire) -- 42401\n",
      "Saved 34 (New Jersey) -- 42401\n",
      "Saved 35 (New Mexico) -- 42401\n",
      "Saved 36 (New York) -- 42401\n",
      "Saved 37 (North Carolina) -- 42401\n",
      "Saved 38 (North Dakota) -- 42401\n",
      "Saved 39 (Ohio) -- 42401\n",
      "Saved 40 (Oklahoma) -- 42401\n",
      "Saved 41 (Oregon) -- 42401\n",
      "Saved 42 (Pennsylvania) -- 42401\n",
      "Saved 44 (Rhode Island) -- 42401\n",
      "Saved 45 (South Carolina) -- 42401\n",
      "Saved 46 (South Dakota) -- 42401\n",
      "Saved 47 (Tennessee) -- 42401\n",
      "Bad URL!\n",
      "No data found for 48 -- 42401\n",
      "Saved 49 (Utah) -- 42401\n",
      "Saved 50 (Vermont) -- 42401\n",
      "Bad URL!\n",
      "No data found for 51 -- 42401\n",
      "Saved 53 (Washington) -- 42401\n",
      "Saved 54 (West Virginia) -- 42401\n"
     ]
    }
   ],
   "source": [
    "all_param_all_states_raw = pd.DataFrame()\n",
    "\n",
    "for param_code in aqi_parameters.code:\n",
    "    all_state_aq_data = pd.DataFrame()\n",
    "\n",
    "    for state_code in state_codes.code:\n",
    "        new_raw_data = aqs_fetcher.daily_data_by_state(state_code, [param_code], bdate, edate)\n",
    "        try:\n",
    "            new_raw_data.to_csv(f'data/{param_code}_state_{state_code}_raw.csv')\n",
    "            print(f'Saved {state_code} ({state_codes.loc[state_codes.code == state_code].state_name.values[0]}) -- {param_code}')\n",
    "            all_state_aq_data = pd.concat([all_state_aq_data, new_raw_data])\n",
    "            sleep(random()*0.25)\n",
    "        except AttributeError:\n",
    "            # we got no data for one of our searches. This is fine, but we don't want to save anything\n",
    "            print(f'No data found for {state_code} -- {param_code}')\n",
    "            pass\n",
    "\n",
    "    all_state_aq_data.to_csv(f'data/{param_code}_all_states_raw.csv')\n",
    "    \n",
    "    all_param_all_states_raw = pd.concat([all_param_all_states_raw, all_state_aq_data])\n",
    "\n",
    "all_param_all_states_raw.to_csv('data/aqi_parameters_all_states_raw.csv')\n",
    "all_param_all_states_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
